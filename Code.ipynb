{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #\"os\" module, which helps us work with files and folders on our computer.\n",
    "import cv2 #use OpenCV, a powerful tool for working with images and videos.\n",
    "import math # \"math\" module, which gives us access to mathematical functions like square roots and trigonometry.\n",
    "import numpy as np #NumPy, which is a library for working with arrays and mathematical operations. \n",
    "import mediapipe as mp #use the MediaPipe library, which is great for tasks like tracking hands or estimating poses in images or videos.\n",
    "import tensorflow as tf #TensorFlow, a popular library for machine learning and deep learning. It helps us build and train neural networks for various tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TensorFlow and Keras Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model #This function is used to load pre-trained neural network models saved in the Hierarchical Data Format (HDF5) file format.\n",
    "from tensorflow.keras import layers, models, datasets #Contains classes for building different layers of a neural network, like dense layers, convolutional layers, etc.\n",
    "from sklearn.model_selection import train_test_split #This function is part of the Scikit-learn library and is used to split datasets into training and testing subsets for model evaluation and validation.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sign Language Phrase Video Writer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = { # These are the keys representing different sign language phrases.\n",
    "    \"Hello\": \"hello_sign_language.avi\",\n",
    "    \"Thank you\": \"thank_you_sign_language.avi\",\n",
    "    \"I love you\": \"i_love_you_sign_language.avi\" #These are the values, representing the file paths of videos for the respective sign language phrases.\n",
    "} #This dictionary stores the names of sign language phrases as keys and the corresponding file paths of videos as values.\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') #This line creates a codec used for writing videos with the XVID codec. The cv2.VideoWriter_fourcc function converts the four-character code 'XVID' into an integer that OpenCV can understand as a codec.\n",
    "video_writers = {\n",
    "    \"Hello\": cv2.VideoWriter(file_paths[\"Hello\"], fourcc, 20.0, (640, 480)),\n",
    "    \"Thank you\": cv2.VideoWriter(file_paths[\"Thank you\"], fourcc, 20.0, (640, 480)),\n",
    "    \"I love you\": cv2.VideoWriter(file_paths[\"I love you\"], fourcc, 20.0, (640, 480)) #It specifies the file path, codec, frame rate (20 frames per second), and frame size (640x480 pixels). Similar initialization is done for the other phrases as well.\n",
    "}#This dictionary stores instances of cv2.VideoWriter objects for each sign language phrase. Each video writer is initialized with the file path, codec, frame rate, and frame size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hand Detection and Tracking with MediaPipe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands # This line imports the \"hands\" module from the MediaPipe library and assigns it to the variable mp_hands. MediaPipe provides a pre-trained model for hand detection and tracking.\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5) #This line initializes a hand detection and tracking object using the Hands class from the MediaPipe module.\n",
    "imgSize = 300 #This line assigns the value 300 to the variable imgSize. This variable likely represents the desired size (in pixels) for the input image to be fed into the hand detection and tracking model.\n",
    "offset = 20 #This line assigns the value 20 to the variable offset. This variable may represent an offset value used for some calculations or adjustments in the subsequent code. Its exact purpose depends on the context of the code that follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real-time Sign Language Capture and Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit the video capture.\n",
      "Press 'h' to save a clip as 'Hello'.\n",
      "Press 't' to save a clip as 'Thank you'.\n",
      "Press 'l' to save a clip as 'I love you'.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Hello' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'Thank you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n",
      "Saved 'I love you' clip.\n"
     ]
    }
   ],
   "source": [
    "def capture_video():\n",
    "    # Open a connection to the default camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Check if the camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to quit the video capture.\")\n",
    "    print(\"Press 'h' to save a clip as 'Hello'.\")\n",
    "    print(\"Press 't' to save a clip as 'Thank you'.\")\n",
    "    print(\"Press 'l' to save a clip as 'I love you'.\")\n",
    "\n",
    "    # Loop to continuously capture frames from the camera\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "        # Check if frame was captured successfully\n",
    "        if not success:\n",
    "            print(\"Error: Could not read frame\")\n",
    "            break\n",
    "        \n",
    "        # Convert the frame from BGR to RGB for MediaPipe processing\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the frame with MediaPipe hand tracking\n",
    "        results = hands.process(frame_rgb)\n",
    "        \n",
    "        # Initialize the hand detection result as None\n",
    "        hand = None\n",
    "        \n",
    "        # Draw hand landmarks and connections on the frame\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp.solutions.drawing_utils.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                # Retrieve bounding box and hand data\n",
    "                # Convert normalized landmarks to pixel coordinates\n",
    "                h, w, _ = frame.shape\n",
    "                x_min = min(landmark.x for landmark in hand_landmarks.landmark) * w\n",
    "                y_min = min(landmark.y for landmark in hand_landmarks.landmark) * h\n",
    "                x_max = max(landmark.x for landmark in hand_landmarks.landmark) * w\n",
    "                y_max = max(landmark.y for landmark in hand_landmarks.landmark) * h\n",
    "                x, y, w, h = int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)\n",
    "                \n",
    "                hand = {'bbox': (x, y, w, h)}\n",
    "\n",
    "        # If a hand is detected, process the frame\n",
    "        if hand:\n",
    "            # Get the bounding box coordinates\n",
    "            x, y, w, h = hand['bbox']\n",
    "\n",
    "            # Skip processing if width or height is zero\n",
    "            if w == 0 or h == 0:\n",
    "                continue\n",
    "\n",
    "            # Create a white background image for padding\n",
    "            imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "\n",
    "            # Make sure the bounding box coordinates do not exceed frame dimensions\n",
    "            x_start = max(0, x - offset)\n",
    "            y_start = max(0, y - offset)\n",
    "            x_end = min(frame.shape[1], x + w + offset)\n",
    "            y_end = min(frame.shape[0], y + h + offset)\n",
    "\n",
    "            # Crop the frame to include only the hand\n",
    "            imgCrop = frame[y_start: y_end, x_start: x_end]\n",
    "            \n",
    "            # Check if the cropped image is empty\n",
    "            if imgCrop.shape[0] == 0 or imgCrop.shape[1] == 0:\n",
    "                continue\n",
    "\n",
    "            # Calculate the aspect ratio of the cropped hand image\n",
    "            aspectRatio = h / w\n",
    "\n",
    "            # Resize the cropped hand image based on the aspect ratio\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap: wCal + wGap] = imgResize\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap: hCal + hGap, :] = imgResize\n",
    "\n",
    "            # Display the cropped and white background images\n",
    "            cv2.imshow('ImageCrop', imgCrop)\n",
    "            cv2.imshow('ImageWhite', imgWhite)\n",
    "\n",
    "            # Save the frames as video clips based on user input\n",
    "            if key == ord('h'):\n",
    "                video_writers[\"Hello\"].write(frame)\n",
    "                print(\"Saved 'Hello' clip.\")\n",
    "            elif key == ord('t'):\n",
    "                video_writers[\"Thank you\"].write(frame)\n",
    "                print(\"Saved 'Thank you' clip.\")\n",
    "            elif key == ord('l'):\n",
    "                video_writers[\"I love you\"].write(frame)\n",
    "                print(\"Saved 'I love you' clip.\")\n",
    "\n",
    "        # Display the frame with landmarks\n",
    "        cv2.imshow(\"Sign Language Capture\", frame)\n",
    "        \n",
    "        # Check for user input\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        \n",
    "    # Release the camera and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Release all video writers\n",
    "    for writer in video_writers.values():\n",
    "        writer.release()\n",
    "    \n",
    "    # Close the MediaPipe hand tracking instance\n",
    "    hands.close()\n",
    "\n",
    "# Call the function to capture video\n",
    "capture_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gesture Recognition Dataset Creation from Video Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames from video files and create dataset\n",
    "def load_video_data(file_paths, label_map):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for label, file_path in file_paths.items():\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        frames = []\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Resize frame to 64x64 and convert to RGB\n",
    "            frame = cv2.resize(frame, (64, 64))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        # Convert list of frames to numpy array and append to data\n",
    "        data.extend(frames)\n",
    "        labels.extend([label_map[label]] * len(frames))\n",
    "    \n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    return data, labels\n",
    "\n",
    "# Define the file paths for each gesture\n",
    "file_paths = {\n",
    "    \"Hello\": \"hello_sign_language.avi\",\n",
    "    \"Thank you\": \"thank_you_sign_language.avi\",\n",
    "    \"I love you\": \"i_love_you_sign_language.avi\"\n",
    "}\n",
    "\n",
    "# Define label map for gestures\n",
    "label_map = {\"Hello\": 0, \"Thank you\": 1, \"I love you\": 2}\n",
    "\n",
    "# Load data\n",
    "data, labels = load_video_data(file_paths, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gesture Recognition Convolutional Neural Network Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # 3 output classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.2937 - loss: 61.1086 - val_accuracy: 0.9659 - val_loss: 0.3389\n",
      "Epoch 2/2\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9945 - loss: 0.1636 - val_accuracy: 1.0000 - val_loss: 5.3920e-05\n",
      "Test accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test))\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sign Language Gesture Classifier Model Saved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"sign_language_gesture_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Long Short-Term Memory (LSTM) Model Training and Evaluation for Gesture Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,219</span> (129.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,219\u001b[0m (129.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,219</span> (129.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,219\u001b[0m (129.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the shape of your input data\n",
    "timesteps = X_train.shape[1]  # Number of time steps in input sequences\n",
    "features = X_train.shape[2]   # Number of features in each time step\n",
    "num_classes = len(np.unique(y_train))  # Number of unique classes in labels\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(units=64, input_shape=(timesteps, features)),  # LSTM layer with 64 units\n",
    "    Dense(units=num_classes, activation='softmax')  # Output layer with softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Real-time Sign Language Gesture Recognition with Pre-trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit real-time detection.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model\n",
    "model = load_model(\"sign_language_gesture_classifier.h5\")\n",
    "\n",
    "# Define label map for gestures\n",
    "label_map = {0: \"Hello\", 1: \"Thank you\", 2: \"I love you\"}\n",
    "\n",
    "# Function to preprocess the frame\n",
    "def preprocess_frame(frame):\n",
    "    # Resize frame to 64x64 and convert to RGB\n",
    "    frame = cv2.resize(frame, (64, 64))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Normalize pixel values\n",
    "    frame = frame / 255.0\n",
    "    # Add an extra dimension to represent batch size (1, height, width, channels)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "    return frame\n",
    "\n",
    "# Open a connection to the default camera (usually the first camera on your system)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera\")\n",
    "else:\n",
    "    print(\"Press 'q' to quit real-time detection.\")\n",
    "\n",
    "# Loop to continuously capture frames from the camera\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Check if frame was captured successfully\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame\")\n",
    "        break\n",
    "    \n",
    "    # Pre-process the frame\n",
    "    preprocessed_frame = preprocess_frame(frame)\n",
    "    \n",
    "    # Predict gesture using the model\n",
    "    predictions = model.predict(preprocessed_frame)\n",
    "    \n",
    "    # Get the predicted label index\n",
    "    predicted_label_index = np.argmax(predictions)\n",
    "    \n",
    "    # Get the predicted label\n",
    "    predicted_label = label_map[predicted_label_index]\n",
    "    \n",
    "    # Display the predicted label on the frame\n",
    "    cv2.putText(frame, f\"Gesture: {predicted_label}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Display the captured frame in a window\n",
    "    cv2.imshow(\"Sign Language Detection\", frame)\n",
    "    \n",
    "    # Check for user input\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord('q'):\n",
    "        # Exit the loop if 'q' is pressed\n",
    "        break\n",
    "\n",
    "# Release the camera and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
